#!/usr/bin/env python3
"""
Voice Pipeline Test - Direct Voice Processing
============================================
Tests the voice processing pipeline directly without WebSocket complexity:
Customer Input â†’ STT â†’ Claude â†’ TTS â†’ Audio Output

This simulates the exact same processing that happens in main.py
"""

import asyncio
import sys
from pathlib import Path
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from enhanced_voice_test import EnhancedVoiceTest

async def test_single_interaction():
    """Test a single voice interaction"""
    print("ğŸ¯ Testing Single Voice Interaction")
    print("=" * 50)
    
    tester = EnhancedVoiceTest()
    
    # Customer data
    customer_data = tester.voice_tester.test_customers["test_customer_1"]
    print(f"ğŸ‘¤ Customer: {customer_data['name']}")
    print(f"ğŸ“ Phone: {customer_data['phone']}")
    print(f"ğŸ’° Loan: {customer_data['loan_id']} - â‚¹{customer_data['amount']}")
    
    # Simulate customer input
    customer_input = "Hello, I received a call about my loan payment. I need help with payment options."
    
    print(f"\nğŸ¤ Customer says: '{customer_input}'")
    print("\nğŸ”„ Processing through voice pipeline...")
    
    # Step 1: STT (Speech-to-Text)
    print("ğŸ“ Step 1: Speech-to-Text...")
    transcript = await tester._simulate_stt(customer_input, customer_data['language_code'])
    print(f"   Result: '{transcript}'")
    
    # Step 2: Claude LLM Processing
    print("ğŸ¤– Step 2: Claude LLM Processing...")
    conversation_id = f"test_{int(asyncio.get_event_loop().time())}"
    
    # Initialize conversation with system prompt
    system_prompt = tester._build_customer_system_prompt(customer_data)
    tester.conversation_history[conversation_id] = [{
        "role": "system",
        "content": system_prompt
    }]
    
    ai_response = await tester._process_with_claude(transcript, conversation_id)
    print(f"   Result: '{ai_response}'")
    
    # Step 3: TTS (Text-to-Speech)
    print("ğŸ”Š Step 3: Text-to-Speech...")
    audio_bytes = await tester._simulate_tts(ai_response, customer_data['language_code'])
    print(f"   Result: {len(audio_bytes)} bytes of audio generated")
    
    # Save the result
    tester._save_conversation_audio(conversation_id, 1, audio_bytes, ai_response)
    
    print("\nâœ… Voice interaction completed successfully!")
    print(f"ğŸ’¾ Audio saved to: conversation_outputs/{conversation_id}/")
    
    return ai_response

async def test_conversation_flow():
    """Test a complete conversation flow"""
    print("\nğŸ¬ Testing Complete Conversation Flow")
    print("=" * 50)
    
    tester = EnhancedVoiceTest()
    
    # Conversation script
    conversation = [
        "Hello, I got a call about my loan payment",
        "I want to know my outstanding amount",
        "What payment options do I have?",
        "Can I pay in installments?",
        "Thank you for your help"
    ]
    
    conversation_id = await tester.simulate_customer_conversation("test_customer_1", conversation)
    
    print(f"\nâœ… Conversation completed!")
    print(f"ğŸ“ Files saved in: conversation_outputs/{conversation_id}/")
    
    return conversation_id

async def main():
    """Main test function"""
    print("ğŸ™ï¸ Voice Pipeline Direct Testing")
    print("=" * 60)
    print("This tests the actual voice processing pipeline:")
    print("   Customer Speech â†’ STT â†’ Claude â†’ TTS â†’ Audio")
    print("=" * 60)
    
    try:
        # Test 1: Single interaction
        await test_single_interaction()
        
        # Test 2: Complete conversation
        await test_conversation_flow()
        
        print("\nğŸ¯ All tests completed successfully!")
        print("\nğŸ“Š What was tested:")
        print("   âœ… Speech-to-Text processing")
        print("   âœ… Claude LLM with collections prompt")
        print("   âœ… Text-to-Speech generation")
        print("   âœ… Multi-turn conversation handling")
        print("   âœ… Audio file generation")
        
        print("\nğŸ’¡ This demonstrates the same pipeline used in main.py")
        print("   The only difference is main.py handles real audio via WebSocket")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
