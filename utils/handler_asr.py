import base64
import tempfile
import io
import os
from pydub import AudioSegment
from sarvamai import SarvamAI
from sarvamai import AsyncSarvamAI, AudioOutput
from fastapi import Body
from .logger import logger


class SarvamHandler:
    def __init__(self, api_key):
        self.client = SarvamAI(api_subscription_key=api_key)
        
        # Language code mapping for proper BCP-47 format
        self.language_map = {
            'en': 'en-IN',
            'hi': 'hi-IN', 
            'bn': 'bn-IN',
            'ta': 'ta-IN',
            'te': 'te-IN',
            'gu': 'gu-IN',
            'kn': 'kn-IN',
            'ml': 'ml-IN',
            'mr': 'mr-IN',
            'pa': 'pa-IN',
            'od': 'od-IN',
            # Already correct formats
            'en-IN': 'en-IN',
            'hi-IN': 'hi-IN',
            'bn-IN': 'bn-IN',
            'ta-IN': 'ta-IN',
            'te-IN': 'te-IN',
            'gu-IN': 'gu-IN',
            'kn-IN': 'kn-IN',
            'ml-IN': 'ml-IN',
            'mr-IN': 'mr-IN',
            'pa-IN': 'pa-IN',
            'od-IN': 'od-IN'
        }

        base_voice_preferences = {
            'en-IN': 'anushka',
            'hi-IN': 'manisha',
            'bn-IN': 'vidya',
            'ta-IN': 'vidya',
            'te-IN': 'arya',
            'gu-IN': 'manisha',
            'kn-IN': 'vidya',
            'ml-IN': 'arya',
            'mr-IN': 'manisha',
            'pa-IN': 'karun',
            'od-IN': 'hitesh',
        }

        self.default_voice = os.getenv("SARVAM_VOICE_DEFAULT", "anushka")
        self.indic_voice_default = os.getenv("SARVAM_VOICE_INDIC_DEFAULT", "vidya")
        self.voice_preferences = {}
        for code, fallback in base_voice_preferences.items():
            env_key = f"SARVAM_VOICE_{code.replace('-', '_').upper()}"
            env_value = os.getenv(env_key)
            if env_value:
                self.voice_preferences[code] = env_value
            else:
                if code.startswith("en"):
                    self.voice_preferences[code] = self.default_voice
                else:
                    self.voice_preferences[code] = fallback or self.indic_voice_default
        # Ensure English fallback always exists
        self.voice_preferences.setdefault('en-IN', self.default_voice)

    def _select_voice(self, lang_code: str) -> str:
        """Pick a Sarvam speaker tuned for the requested language, with env overrides."""
        if not lang_code:
            return self.default_voice

        # Direct mapping on normalized language code
        if lang_code in self.voice_preferences:
            return self.voice_preferences[lang_code]

        # Allow simple overrides like SARVAM_VOICE_HI
        short_key = lang_code.split('-')[0].upper()
        env_short = os.getenv(f"SARVAM_VOICE_{short_key}")
        if env_short:
            return env_short

        # Attempt prefix match from existing preferences (hi-IN -> hi, etc.)
        for code, speaker in self.voice_preferences.items():
            if code.split('-')[0] == lang_code.split('-')[0]:
                return speaker

        # Fallback: use Indic default for non-English languages
        if not lang_code.lower().startswith('en'):
            return self.indic_voice_default

        return self.default_voice

    def _normalize_language_code(self, lang: str) -> str:
        """Convert language code to proper BCP-47 format expected by Sarvam API"""
        normalized = self.language_map.get(lang.lower(), 'en-IN')
        logger.tts.info(f"üåç Language mapping: {lang} ‚Üí {normalized}")
        return normalized

    def _slin_to_wav_file(self, slin_bytes) -> str:
        audio = AudioSegment(
            slin_bytes,
            sample_width=2,  # 16-bit PCM
            frame_rate=8000,
            channels=1
        )
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
            audio.export(f.name, format="wav")
            return f.name

    def transcribe_from_payload(self, audio_buffer: bytes) -> str:
        logger.tts.info("üéôÔ∏è Converting SLIN base64 to WAV")

        # Convert SLIN (raw 8kHz PCM mono) to WAV
        audio = AudioSegment(
            data=audio_buffer,
            sample_width=2,  # 16-bit PCM
            frame_rate=8000,
            channels=1
        )
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
            audio.export(f.name, format="wav")
            wav_path = f.name
        logger.tts.info("üöÄ Sending WAV to Sarvam API")
        # Call Sarvam REST API directly
        with open(wav_path, "rb") as wav_file:
            response = self.client.speech_to_text.transcribe(
                file=wav_file,
                model="saarika:v2.5",
                language_code="unknown"  # Make sure this matches your subscription
            )
        logger.tts.info(f"üìù Transcript received: {response.transcript}")
        return response.transcript
    
    async def synthesize_tts_end(self, text: str, lang: str) -> bytes:
        logger.tts.info(f"üîÅ Starting text-to-speech for: {text} in {lang}")

        try:
            lang_code = self._normalize_language_code(lang)
            speaker = self._select_voice(lang_code)

            response = self.client.text_to_speech.convert(
                text=text,
                target_language_code=lang_code,
                speaker=speaker,
                model="bulbul:v2"
            )
            audio_base64 = response.audios[0] if response.audios else None
            if not audio_base64:
                logger.tts.error("‚ùå No audio data returned from API.")
                return None
            
            audio_bytes = base64.b64decode(audio_base64)
            
            # The audio is likely mp3, convert it to 8kHz mono 16-bit PCM (slin)
            try:
                audio_segment = AudioSegment.from_file(io.BytesIO(audio_bytes), format="mp3")
            except Exception as dec_err:
                logger.tts.error(f"‚ùå Decode mp3 failed: {dec_err}")
                return None

            slin_audio = audio_segment.set_frame_rate(8000).set_channels(1).set_sample_width(2)
            raw_pcm = slin_audio.raw_data
            size = len(raw_pcm)
            if raw_pcm[:4] == b'RIFF' and size > 44:
                # Safety: if pydub ever returned WAV with header (shouldn't for raw_data) remove it
                logger.tts.warning("‚ö†Ô∏è Unexpected RIFF header in raw_data ‚Äì stripping")
                raw_pcm = raw_pcm[44:]
                size = len(raw_pcm)
            logger.tts.info(f"‚úÖ Audio ready PCM size={size} bytes, first10={raw_pcm[:10].hex()}")
            if size < 200:
                logger.tts.warning("‚ö†Ô∏è Very small audio payload ‚Äì may be silence")
            return raw_pcm

        except Exception as e:
            logger.tts.error(f"‚ùå An error occurred: {e}")
            import traceback
            traceback.print_exc()
            return None
   
    async def synthesize_tts(self, text: str, lang: str) -> bytes:
        """Smart TTS synthesis with translation support"""
        logger.tts.info("üîÅ Starting text-to-speech synthesis (with translation)")

        try:
            # Normalize language code to BCP-47 format
            lang_code = self._normalize_language_code(lang)
            speaker = self._select_voice(lang_code)
            
            # Check if translation is needed
            if not self._is_text_in_target_language(text, lang_code):
                logger.tts.info(f"üåê Text needs translation to {lang_code}")
                try:
                    response = self.client.translate.translate(
                        input=text,
                        source_language_code="en-IN",  # Assume English source
                        target_language_code=lang_code,
                        model="mayura:v1",
                        enable_preprocessing=True
                    )
                    
                    if response and hasattr(response, 'translated_text'):
                        translated_text = response.translated_text
                        logger.tts.info(f"üî§ Translated text: {translated_text}")
                    else:
                        logger.tts.warning("‚ùå Translation response is empty, using original text")
                        translated_text = text
                        
                except Exception as e:
                    logger.tts.error(f"‚ùå Translation failed: {e}")
                    logger.tts.info(f"üî§ Using original text: {text}")
                    translated_text = text
            else:
                logger.tts.info(f"‚úÖ Text already in target language ({lang_code})")
                translated_text = text

            logger.tts.info("üé§ Generating TTS audio...")
            
            # Generate TTS with optimized parameters for bulbul:v2
            response = self.client.text_to_speech.convert(
                text=translated_text,
                target_language_code=lang_code,
                model="bulbul:v2",
                speaker=speaker,
                pitch=1.0,        # Natural pitch
                pace=1.0,         # Natural speaking pace
                loudness=1.0,     # Natural volume
                speech_sample_rate=8000, # Optimized for telephony (correct parameter name)
                enable_preprocessing=True  # Better handling of mixed content
            )
            
            if not response or not hasattr(response, 'audios') or not response.audios:
                logger.tts.error("‚ùå No audio data returned from Sarvam TTS")
                return None
                
            audio_data = response.audios[0]
            logger.tts.info(f"‚úÖ Received audio data from Sarvam API (length: {len(audio_data)})")
            
            # Handle base64 encoded audio
            if isinstance(audio_data, str):
                try:
                    audio_bytes = base64.b64decode(audio_data)
                    logger.tts.info(f"üîì Decoded base64 audio ({len(audio_bytes)} bytes)")
                except Exception as e:
                    logger.tts.error(f"‚ùå Failed to decode base64 audio: {e}")
                    return None
            else:
                audio_bytes = audio_data
                
        except Exception as e:
            logger.tts.error(f"‚ùå TTS generation failed: {e}")
            return None

        # Step 3: Convert to SLIN format with better error handling
        try:
            logger.tts.info("üéß Converting audio to SLIN format...")
            
            # Create temporary file to handle audio conversion
            import tempfile
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_file.write(audio_bytes)
                temp_file.flush()
                
                # Load audio using pydub with explicit format
                try:
                    audio_segment = AudioSegment.from_file(temp_file.name)
                    logger.tts.info(f"üìä Original audio: {audio_segment.frame_rate}Hz, {audio_segment.channels}ch, {len(audio_segment)}ms")
                except:
                    # Try as WAV if MP3 fails
                    audio_segment = AudioSegment.from_wav(temp_file.name)
                    logger.tts.info(f"üìä WAV audio loaded: {audio_segment.frame_rate}Hz, {audio_segment.channels}ch, {len(audio_segment)}ms")
                
                # Convert to SLIN format (8kHz, mono, 16-bit)
                slin_audio = audio_segment.set_frame_rate(8000).set_channels(1).set_sample_width(2)
                final_bytes = slin_audio.raw_data
                
                # Clean up temp file
                import os
                os.unlink(temp_file.name)
                
            logger.tts.info(f"‚úÖ SLIN audio ready: {len(final_bytes)} bytes, 8kHz mono")
            
            # Validate audio data
            if len(final_bytes) < 1000:  # Less than ~62ms of audio
                logger.tts.warning("‚ö†Ô∏è Very short audio generated, may be silence")
                
            return final_bytes
            
        except Exception as e:
            logger.tts.error(f"‚ùå Audio conversion failed: {e}")
            import traceback
            logger.tts.error(f"‚ùå Conversion traceback: {traceback.format_exc()}")
            return None

    async def synthesize_tts_direct(self, text: str, lang: str) -> bytes:
        """Direct TTS synthesis without translation - optimized for Sarvam API v2"""
        logger.tts.info("üîÅ Starting direct text-to-speech synthesis (no translation)")

        try:
            # Normalize language code to BCP-47 format
            lang_code = self._normalize_language_code(lang)
            speaker = self._select_voice(lang_code)
            
            logger.tts.info("üé§ Generating direct TTS audio...")
            response = self.client.text_to_speech.convert(
                text=text,
                target_language_code=lang_code,
                speaker=speaker,  # Compatible speaker for bulbul:v2
                pitch=0.0,        # Natural pitch
                pace=1.0,         # Natural pace  
                loudness=1.0,     # Natural loudness
                speech_sample_rate=8000,  # 8kHz for telephony
                enable_preprocessing=True,  # Better mixed-language handling
                model="bulbul:v2"  # Latest stable model
            )
            
            if not response or not hasattr(response, 'audios') or not response.audios:
                logger.tts.error("‚ùå No audio data returned from Sarvam TTS")
                return None
                
            audio_data = response.audios[0]
            logger.tts.info(f"‚úÖ Received direct audio data from Sarvam API (length: {len(audio_data)})")
            
            # Handle base64 encoded audio
            if isinstance(audio_data, str):
                try:
                    audio_bytes = base64.b64decode(audio_data)
                    logger.tts.info(f"üîì Decoded base64 audio ({len(audio_bytes)} bytes)")
                except Exception as e:
                    logger.tts.error(f"‚ùå Failed to decode base64 audio: {e}")
                    return None
            else:
                audio_bytes = audio_data
            
            # Convert to SLIN format with better error handling
            logger.tts.info("üéß Converting direct audio to SLIN format...")
            
            # Create temporary file to handle audio conversion
            import tempfile
            import os
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_file.write(audio_bytes)
                temp_file.flush()
                
                # Load audio using pydub with explicit format
                try:
                    audio_segment = AudioSegment.from_file(temp_file.name)
                    logger.tts.info(f"üìä Direct audio: {audio_segment.frame_rate}Hz, {audio_segment.channels}ch, {len(audio_segment)}ms")
                except:
                    # Try as WAV if MP3 fails
                    audio_segment = AudioSegment.from_wav(temp_file.name)
                    logger.tts.info(f"üìä Direct WAV audio: {audio_segment.frame_rate}Hz, {audio_segment.channels}ch, {len(audio_segment)}ms")
                
                # Convert to SLIN format (8kHz, mono, 16-bit)
                slin_audio = audio_segment.set_frame_rate(8000).set_channels(1).set_sample_width(2)
                final_bytes = slin_audio.raw_data
                
                # Clean up temp file
                os.unlink(temp_file.name)
                
            logger.tts.info(f"‚úÖ Direct SLIN audio ready: {len(final_bytes)} bytes, 8kHz mono")
            
            # Validate audio data
            if len(final_bytes) < 1000:  # Less than ~62ms of audio
                logger.tts.warning("‚ö†Ô∏è Very short direct audio generated, may be silence")
                
            return final_bytes
            
        except Exception as e:
            logger.tts.error(f"‚ùå Direct TTS generation failed: {e}")
            import traceback
            logger.tts.error(f"‚ùå Direct TTS traceback: {traceback.format_exc()}")
            return None

    def _is_text_in_target_language(self, text: str, lang: str) -> bool:
        """Simple heuristic to check if text is already in target language"""
        # For Hindi/Devanagari languages
        if lang.startswith('hi'):
            return any('\u0900' <= char <= '\u097F' for char in text)
        # For Tamil
        elif lang.startswith('ta'):
            return any('\u0B80' <= char <= '\u0BFF' for char in text)
        # For Telugu
        elif lang.startswith('te'):
            return any('\u0C00' <= char <= '\u0C7F' for char in text)
        # For Kannada
        elif lang.startswith('kn'):
            return any('\u0C80' <= char <= '\u0CFF' for char in text)
        # For Malayalam
        elif lang.startswith('ml'):
            return any('\u0D00' <= char <= '\u0D7F' for char in text)
        # For Gujarati
        elif lang.startswith('gu'):
            return any('\u0A80' <= char <= '\u0AFF' for char in text)
        # For Marathi (uses Devanagari like Hindi)
        elif lang.startswith('mr'):
            return any('\u0900' <= char <= '\u097F' for char in text)
        # For Bengali
        elif lang.startswith('bn'):
            return any('\u0980' <= char <= '\u09FF' for char in text)
        # For Punjabi/Gurmukhi
        elif lang.startswith('pa'):
            return any('\u0A00' <= char <= '\u0A7F' for char in text)
        # For Oriya
        elif lang.startswith('or'):
            return any('\u0B00' <= char <= '\u0B7F' for char in text)
        # Default: assume English text needs translation to non-English languages
        return lang.startswith('en')
   
    async def synthesize_tts_test_NOT_IN_USE(self, text: str) -> bytes:
        logger.tts.debug("synthesize_tts_test_NOT_IN_USE called")

        async with self.client.text_to_speech_streaming.connect(model="bulbul:v2") as ws:
            logger.tts.debug("Inside streaming TTS connection")

            # Configure TTS stream
            await ws.configure(
                target_language_code="en-IN",
                speaker=self._select_voice("en-IN")
            )

            # Send text for conversion
            await ws.convert(text)
            logger.tts.debug("Text sent for conversion")

            # Optional: finalize stream
            await ws.flush()
            logger.tts.debug("Stream flushed")

            # Collect and decode audio chunks
            audio_data = bytearray()
            async for message in ws:
                if isinstance(message, AudioOutput):
                    audio_chunk = base64.b64decode(message.data.audio)
                    audio_data.extend(audio_chunk)

            logger.tts.info("üé§ TTS generation complete")
            return bytes(audio_data)
